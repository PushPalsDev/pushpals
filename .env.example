# ─── PushPals Environment ─────────────────────────────────────────────
# Copy to .env and fill in values.  Bun auto-loads .env at the repo root.
# ─────────────────────────────────────────────────────────────────────

# ─── Data ────────────────────────────────────────────────────────────
# Base directory for SQLite databases (default: <project_root>/outputs/data)
# The entire outputs/ dir is gitignored.
# PUSHPALS_DATA_DIR=./outputs/data

# Override individual DB paths (absolute or relative to PUSHPALS_DATA_DIR)
# PUSHPALS_DB_PATH=         # server DB (default: <data_dir>/pushpals.db)
# AGENT_REMOTE_DB_PATH=     # agent-remote idempotency DB (default: <data_dir>/agent-remote-state.db)

# ─── Server ──────────────────────────────────────────────────────────
# Port the PushPals server listens on (default 3001)
# PUSHPALS_PORT=3001

# Optional shared auth token — if set, server + agents validate Bearer tokens
# PUSHPALS_AUTH_TOKEN=

# Set to any value to enable verbose request logging on the server
# DEBUG=1

# ─── LLM Provider (choose ONE section) ──────────────────────────────
#
# The agent-remote auto-detects which provider to use based on which
# API key / endpoint is set.  Priority: OPENAI → ANTHROPIC → LLM_ENDPOINT → Ollama.

# — OpenAI ─────────────────────────────────
# OPENAI_API_KEY=
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_API_ENDPOINT=https://api.openai.com

# — Anthropic ──────────────────────────────
# ANTHROPIC_API_KEY=
# ANTHROPIC_MODEL=claude-sonnet-4-20250514
# ANTHROPIC_API_ENDPOINT=https://api.anthropic.com

# — Generic OpenAI-compatible (Ollama / vLLM / LM Studio) ──────────
# LLM_ENDPOINT is the base URL — the client appends /v1/chat/completions.
# OPENAI_API_KEY / ANTHROPIC_API_KEY must be unset for this to activate.
# LLM_ENDPOINT=http://localhost:11434
# LLM_MODEL=gpt-oss:20b
# LLM_API_KEY=ollama

# ─── Agent-local planner (optional, separate from agent-remote LLM) ──
# PLANNER_ENDPOINT=http://localhost:11434/api/chat
# PLANNER_MODEL=gpt-oss:20b
# PLANNER_API_KEY=
